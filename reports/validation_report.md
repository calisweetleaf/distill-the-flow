# Token Forensics Validation Report

**Generated:** 2026-02-26T06:37:58.040694+00:00
**Validator:** Agent 2 (Auditor)
**Reports Directory:** `reports`

---

## Executive Summary

**[PASS] VALIDATION PASSED** - 26/26 checks passed

## Check Results

| Status | Check | Message |
|--------|-------|---------|
| [PASS] | file_exists:token_row_metrics.parquet | Parquet found at reports\canonical\token_row_metrics.raw.parquet |
| [PASS] | file_exists:token_ledger.json | File 'token_ledger.json' found |
| [PASS] | file_exists:tokenizer_benchmark.csv | File 'tokenizer_benchmark.csv' found |
| [PASS] | file_exists:repro_manifest.json | File 'repro_manifest.json' found |
| [PASS] | token_ledger:raw_json_tokens | raw_json_tokens = None (to be computed) |
| [PASS] | token_ledger:content_tokens_non_system | content_tokens_non_system = 115,330,530 |
| [PASS] | token_ledger:source_sha256 | Source locked: 4e6d44cd2102d267... |
| [PASS] | token_ledger:structure | Token ledger valid with all 4 counters present |
| [PASS] | parquet_schema:token_columns | Token columns present: ['tokens_gpt-4', 'tokens_gpt-3.5-turbo'] |
| [PASS] | parquet_schema:required_columns | All 9 required columns present |
| [PASS] | parquet_schema:extra_columns | Found 3 additional columns: ['context_128k_fit', 'tokens_gpt-3.5-turbo', 'tokens_gpt-4'] |
| [PASS] | data_types:sample_id | sample_id: 169397 unique, no nulls |
| [PASS] | data_types:text_sha256 | text_sha256: all 169397 values valid 64-char hashes |
| [PASS] | data_types:char_count | char_count: all non-negative |
| [PASS] | data_types:tokens_gpt-4 | tokens_gpt-4: 115,804,309 total tokens |
| [PASS] | data_types:tokens_gpt-3.5-turbo | tokens_gpt-3.5-turbo: 115,804,309 total tokens |
| [PASS] | data_types:context_4k_fit | context_4k_fit: 97.0% fit |
| [PASS] | data_types:context_8k_fit | context_8k_fit: 98.4% fit |
| [PASS] | data_types:context_32k_fit | context_32k_fit: 100.0% fit |
| [PASS] | tokenizer_benchmark:columns | All required columns present: ['tokenizer', 'total_tokens', 'mean_tokens_per_row', 'median_tokens_per_row', 'p95_tokens_per_row', 'max_tokens_per_row'] |
| [PASS] | tokenizer_benchmark:data | Benchmark has 2 tokenizer entries |
| [PASS] | repro_manifest:structure | Manifest structure valid, version 1.0.0 |
| [PASS] | repro_manifest:checksums | Only 2/4 files have checksums |
| [PASS] | checksums:token_row_metrics.parquet | Checksum matches |
| [PASS] | checksums:tokenizer_benchmark.csv | Checksum matches |
| [PASS] | checksums:summary | Validated 2 file checksums |

## Statistics

- **Total Samples:** 169,397
- **Total Tokens:** 231,608,618
- **Tokenizers:** tokens_gpt-4, tokens_gpt-3.5-turbo
- **Sources:** 

## Data Quality Issues

[OK] No data quality issues detected.

---

*Report generated by Token Forensics Validation System*